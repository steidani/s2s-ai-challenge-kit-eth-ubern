{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2fc44d",
   "metadata": {},
   "source": [
    "# Prepare data from S2S Database at KIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc4358",
   "metadata": {},
   "source": [
    "* load data ensemble-wise for each forecast initial time and filetype(P, SDA, TH, ...)\n",
    "* compute weekly means\n",
    "* do this for all forecast initial times\n",
    "\n",
    "! this takes very long depending on the filetype, don't try for all forecast initial times at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3376fe2",
   "metadata": {},
   "source": [
    "### Todo: if aggregate_weekly is used with s2s= True, the mapping from time to forecast_time is wrong for variables without a value at lead_time = 0. \n",
    "also: rename variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d82de",
   "metadata": {},
   "source": [
    "Most of the functions used in this notebook can be found in helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd68bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##shift coods: flip_antimeridian in helper_functions.py: not used so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten# you don't need tensorflow here, this is here because of problems with my env on windows\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xarray as xr\n",
    "xr.set_options(display_style='text')\n",
    "\n",
    "\n",
    "\n",
    "from dask.utils import format_bytes\n",
    "import xskillscore as xs\n",
    "\n",
    "%matplotlib inline \n",
    "#so that figures appear again\n",
    "\n",
    "#for prediction\n",
    "from scripts import make_probabilistic\n",
    "from scripts import add_valid_time_from_forecast_reference_time_and_lead_time\n",
    "from scripts import skill_by_year\n",
    "from scripts import add_year_week_coords\n",
    "\n",
    "\n",
    "from helper_functions import  concat_ensemble, aggregate_weekly, get_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"Z:\"#\"../../S2S_data/\"\n",
    "var = 'SDA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194eee27",
   "metadata": {},
   "source": [
    "### for one ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2s = xr.open_dataset(f'{datapath}/ecmwf/2017/20170101/TH20170101_00_PF_01', engine = 'h5netcdf')\n",
    "#if without tensorflow, h5netcdf throws an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2s#.tp.isel(time = 0).where( ds_s2s.tp.isel(time = 0) != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba602f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get filenames\n",
    "filenames = get_filenames(datapath, model = 'ecmwf', date = str(ds_s2s.time[0].values), file_type = var)\n",
    "filenames\n",
    "\n",
    "#str(ds_s2s.time[0].values) does not work if ds_s2s contains SDA data since there \n",
    "#forecast_time is shifted by one day compared to the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376abfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open and concat files  #this takes a few minutes\n",
    "ds_s2s = concat_ensemble(filenames, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc759b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##compute weekly aggregates for each forecast init time\n",
    "ds_w = ds_s2s.map(aggregate_weekly, s2s = True)\n",
    "#ds_w = ds_w.map(ensure_attributes, biweekly=False) this downloads data, so omit this step            \n",
    "ds_w = ds_w.sortby('forecast_time')\n",
    "ds_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b4800",
   "metadata": {},
   "source": [
    "### for multiple forecast initial dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723275ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dates where labels are available\n",
    "cache_path = '../data'\n",
    "dat  = xr.open_zarr(f'{cache_path}/ecmwf_hindcast-input_2000-2019_biweekly_deterministic.zarr', consolidated=True)\n",
    "thursdays_2000_2019 = [str(e)[0:10] for e in dat.forecast_time.values]\n",
    "thursdays_2000_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38905c99",
   "metadata": {},
   "source": [
    "### for one forecast initial time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165fae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_single_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(thursdays_2000_2019[0]) ##some dates won't be found\n",
    "#datapath = \"Z:\"#\"../../S2S_data/\"\n",
    "#var = 'TH'\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a few minutes, does the same than then the functions above, just now combined in one function\n",
    "ds_weekly_ = get_single_forecast(datapath, date, var)\n",
    "ds_weekly_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416fd6d3",
   "metadata": {},
   "source": [
    "### for multiple forecast initial dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "thursdays_2000_2019[0:53]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573a673",
   "metadata": {},
   "source": [
    "deprecated\n",
    "def get_multiple_forecasts(datapath, date_list, file_type):\n",
    "    ds_weekly_list = []\n",
    "    for d in date_list:\n",
    "        print(d)\n",
    "        ds_weekly = get_single_forecast(datapath, d, file_type)\n",
    "        ds_weekly_list.append(ds_weekly)\n",
    "        #if d%10 == 0: #maybe better to concat after every tenth dataset\n",
    "        #    if d == 10:\n",
    "    ds_weekly_multiple = xr.concat(ds_weekly_list, dim = 'forecast_time')            \n",
    "    return ds_weekly_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d80ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import replace_unavailable_dates, get_multiple_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd56ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##only first 3 since this takes VERY long (more than 10 minutes)\n",
    "ds_weekly_multiple = get_multiple_forecasts(datapath, thursdays_2000_2019[0:3], var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39938c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_weekly_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62771ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_weekly_multiple.isel(lead_time = 0).mean(('realization', 'forecast_time'))['2t'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_weekly_multiple.to_netcdf('/../data/s2s_weekly_hindcasts_ecmwf_t2m_2000.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c529b",
   "metadata": {},
   "source": [
    "### construct monday dates for 2000 - 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4284d4a",
   "metadata": {},
   "source": [
    "#### Thursdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../template/data'\n",
    "dat_2020 = xr.open_zarr(f'{cache_path}/ecmwf_forecast-input_2020_biweekly_deterministic.zarr', consolidated=True)\n",
    "#dat_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb902f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dat_2020.forecast_time[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ea82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[dat_2020.forecast_time.values]###convert to string itemwise...\n",
    "dates_2020 = [str(e) for e in dat_2020.forecast_time.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ec69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the Thursdays\n",
    "days = [str(e)[5:10] for e in dat_2020.forecast_time.values]\n",
    "year = [str(e)[0:4] for e in dat_2020.forecast_time.values]\n",
    "\n",
    "print(days)\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1e100",
   "metadata": {},
   "source": [
    "#### Mondays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mondays_2020 = pd.read_csv(\"../../S2S_data/Mondays2020.csv\")#, index_col = False, sep = ';')#.reset_index(drop=True, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mondays_2020['Mondays 2020'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mondays = mondays_2020['Mondays 2020'].str[5:10].to_list()#[str(e)[5:10] for e in list(mondays_2020)]\n",
    "#year = [str(e)[0:4] for e in dat_2020.forecast_time.values]\n",
    "\n",
    "print(mondays)\n",
    "#print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfdc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2000,2018)\n",
    "years = np.repeat(years, 52)\n",
    "years = list(years)\n",
    "years = [str(e) for e in years]\n",
    "len(years)/18###only 52 mondays in 2020..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3054f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "monday_dates = [ '-'.join([years[i],mondays[i%len(mondays)]]) for i in range(0,len(years))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b76b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "monday_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out to avoid that file is overwritten\n",
    "#pd.DataFrame(monday_dates).to_csv(\"../../S2S_data/Mondays2000_2017.csv\", index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
