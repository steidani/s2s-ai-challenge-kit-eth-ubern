{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e654fd",
   "metadata": {},
   "source": [
    "\n",
    "Compute RPSS and plot achieved RPSS on map and as time series.\n",
    "Also compute RPSS for each variable and lead time separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ff6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Reshape, Dot, Add, Activation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "xr.set_options(display_style='text')\n",
    "\n",
    "import xskillscore as xs\n",
    "\n",
    "\n",
    "\n",
    "from scripts import skill_by_year, add_year_week_coords\n",
    "from helper_ml_data import load_data, get_basis, rm_annualcycle, rm_tercile_edges, rm_tercile_edges1, DataGenerator1, single_prediction, skill_by_year_single\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from scripts import assert_predictions_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a13a0-f44f-488a-a52e-c75705732755",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'server'\n",
    "\n",
    "v= 't2m'\n",
    "lead_output = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dbe219-723a-4690-81f5-b928526b6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridcellwise_rpss(fct_p, obs_p, v):\n",
    "    #def compute_rpss():\n",
    "    # climatology\n",
    "    clim_p = xr.DataArray([1/3, 1/3, 1/3], dims='category', coords={'category':['below normal', 'near normal', 'above normal']}).to_dataset(name='tp')\n",
    "    clim_p['t2m'] = clim_p['tp']\n",
    "    \n",
    "    clim_p = clim_p[v]\n",
    "    \n",
    "    ## RPSS\n",
    "    # rps_ML\n",
    "    rps_ML = xs.rps(obs_p, fct_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "    # rps_clim\n",
    "    rps_clim = xs.rps(obs_p, clim_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "    \n",
    "    # rpss\n",
    "    rpss = 1 - (rps_ML / rps_clim)\n",
    "    return rpss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ae716-6d0c-465c-a29a-a1074acb02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_by_year_byvar_andlead(preds, cache_path = '../../../../Data/s2s_ai/data', adapt=False):\n",
    "    \"\"\"Returns pd.Dataframe of RPSS per year.\"\"\"\n",
    "    # similar verification_RPSS.ipynb\n",
    "    # as scorer bot but returns a score for each year\n",
    "    import xarray as xr\n",
    "    import xskillscore as xs\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    xr.set_options(keep_attrs=True)\n",
    "    \n",
    "    # from root\n",
    "    #renku storage pull data/forecast-like-observations_2020_biweekly_terciled.nc\n",
    "    #renku storage pull data/hindcast-like-observations_2000-2019_biweekly_terciled.nc\n",
    "    #cache_path = '../data'\n",
    "    if 2020 in preds.forecast_time.dt.year:\n",
    "        obs_p = xr.open_dataset(f'{cache_path}/forecast-like-observations_2020_biweekly_terciled.nc').sel(forecast_time=preds.forecast_time)\n",
    "    else:\n",
    "        obs_p = xr.open_dataset(f'{cache_path}/hindcast-like-observations_2000-2019_biweekly_terciled.zarr', engine='zarr').sel(forecast_time=preds.forecast_time)\n",
    "    \n",
    "    # ML probabilities\n",
    "    fct_p = preds\n",
    "\n",
    "    \n",
    "    # climatology\n",
    "    clim_p = xr.DataArray([1/3, 1/3, 1/3], dims='category', coords={'category':['below normal', 'near normal', 'above normal']}).to_dataset(name='tp')\n",
    "    clim_p['t2m'] = clim_p['tp']\n",
    "    \n",
    "    if adapt:\n",
    "        # select only obs_p where fct_p forecasts provided\n",
    "        for c in ['longitude', 'latitude', 'forecast_time', 'lead_time']:\n",
    "            obs_p = obs_p.sel({c:fct_p[c]})\n",
    "        obs_p = obs_p[list(fct_p.data_vars)]\n",
    "        clim_p = clim_p[list(fct_p.data_vars)]\n",
    "    \n",
    "    else:\n",
    "        # check inputs\n",
    "        assert_predictions_2020(obs_p)\n",
    "        assert_predictions_2020(fct_p)\n",
    "        \n",
    "    # rps_ML\n",
    "    rps_ML = xs.rps(obs_p, fct_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "    # rps_clim\n",
    "    rps_clim = xs.rps(obs_p, clim_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "\n",
    "    ## RPSS\n",
    "    # penalize # https://renkulab.io/gitlab/aaron.spring/s2s-ai-challenge-template/-/issues/7\n",
    "    expect = obs_p.sum('category')\n",
    "    expect = expect.where(expect > 0.98).where(expect < 1.02)  # should be True if not all NaN\n",
    "\n",
    "    # https://renkulab.io/gitlab/aaron.spring/s2s-ai-challenge-template/-/issues/50\n",
    "    rps_ML = rps_ML.where(expect, other=2)  # assign RPS=2 where value was expected but NaN found\n",
    "\n",
    "    # following Weigel 2007: https://doi.org/10.1175/MWR3280.1\n",
    "    rpss = 1 - (rps_ML.groupby('forecast_time.year').mean() / rps_clim.groupby('forecast_time.year').mean())\n",
    "    # clip\n",
    "    rpss = rpss.clip(-10, 1)\n",
    "    \n",
    "    # weighted area mean\n",
    "    weights = np.cos(np.deg2rad(np.abs(rpss.latitude)))\n",
    "    # spatially weighted score averaged over lead_times and variables to one single value\n",
    "    scores = rpss.sel(latitude=slice(None, -60)).weighted(weights).mean('latitude').mean('longitude')\n",
    "    scores = scores.to_array()#.mean(['lead_time', 'variable'])\n",
    "    return scores.to_dataframe('RPSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7df1c9-985c-483e-b31f-47a4c0d08cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_by_year_old(preds, cache_path = '../../../../Data/s2s_ai/data',adapt=False):\n",
    "    \"\"\"Returns pd.Dataframe of RPSS per year.\"\"\"\n",
    "    # similar verification_RPSS.ipynb\n",
    "    # as scorer bot but returns a score for each year\n",
    "    import xarray as xr\n",
    "    import xskillscore as xs\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    xr.set_options(keep_attrs=True)\n",
    "    \n",
    "    # from root\n",
    "    #renku storage pull data/forecast-like-observations_2020_biweekly_terciled.nc\n",
    "    #renku storage pull data/hindcast-like-observations_2000-2019_biweekly_terciled.nc\n",
    "   # cache_path = '../template/data'\n",
    "    if 2020 in preds.forecast_time.dt.year:\n",
    "        obs_p = xr.open_dataset(f'{cache_path}/forecast-like-observations_2020_biweekly_terciled.nc').sel(forecast_time=preds.forecast_time)\n",
    "    else:\n",
    "        obs_p = xr.open_dataset(f'{cache_path}/hindcast-like-observations_2000-2019_biweekly_terciled.zarr', engine='zarr').sel(forecast_time=preds.forecast_time)\n",
    "    \n",
    "    # ML probabilities\n",
    "    fct_p = preds\n",
    "\n",
    "    \n",
    "    # climatology\n",
    "    clim_p = xr.DataArray([1/3, 1/3, 1/3], dims='category', coords={'category':['below normal', 'near normal', 'above normal']}).to_dataset(name='tp')\n",
    "    clim_p['t2m'] = clim_p['tp']\n",
    "    \n",
    "    if adapt:\n",
    "        # select only obs_p where fct_p forecasts provided\n",
    "        for c in ['longitude', 'latitude', 'forecast_time', 'lead_time']:\n",
    "            obs_p = obs_p.sel({c:fct_p[c]})\n",
    "        obs_p = obs_p[list(fct_p.data_vars)]\n",
    "        clim_p = clim_p[list(fct_p.data_vars)]\n",
    "    \n",
    "    else:\n",
    "        # check inputs\n",
    "        assert_predictions_2020(obs_p)\n",
    "        assert_predictions_2020(fct_p)\n",
    "    \n",
    "    ## RPSS\n",
    "    # rps_ML\n",
    "    rps_ML = xs.rps(obs_p, fct_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "    # rps_clim\n",
    "    rps_clim = xs.rps(obs_p, clim_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "    \n",
    "    # rpss\n",
    "    rpss = 1 - (rps_ML / rps_clim)\n",
    "    \n",
    "    # https://renkulab.io/gitlab/aaron.spring/s2s-ai-challenge-template/-/issues/7\n",
    "\n",
    "    # penalize\n",
    "    penalize = obs_p.where(fct_p!=1, other=-10).mean('category')\n",
    "    rpss = rpss.where(penalize!=0, other=-10)\n",
    "\n",
    "    # clip\n",
    "    rpss = rpss.clip(-10, 1)\n",
    "\n",
    "    # average over all forecasts\n",
    "    rpss = rpss.groupby('forecast_time.year').mean()\n",
    "    \n",
    "    # weighted area mean\n",
    "    weights = np.cos(np.deg2rad(np.abs(rpss.latitude)))\n",
    "    # spatially weighted score averaged over lead_times and variables to one single value\n",
    "    scores = rpss.sel(latitude=slice(None, -60)).weighted(weights).mean('latitude').mean('longitude')\n",
    "    scores = scores.to_array().mean(['lead_time', 'variable'])\n",
    "    return scores.to_dataframe('RPSS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe096b-febc-4de4-b7e9-925b39bae509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_by_year_old_single(preds, cache_path = '../../../../Data/s2s_ai/data',adapt=False):\n",
    "    \"\"\"Returns pd.Dataframe of RPSS per year.\"\"\"\n",
    "    # similar verification_RPSS.ipynb\n",
    "    # as scorer bot but returns a score for each year\n",
    "    import xarray as xr\n",
    "    import xskillscore as xs\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    xr.set_options(keep_attrs=True)\n",
    "    \n",
    "    # from root\n",
    "    #renku storage pull data/forecast-like-observations_2020_biweekly_terciled.nc\n",
    "    #renku storage pull data/hindcast-like-observations_2000-2019_biweekly_terciled.nc\n",
    "   # cache_path = '../template/data'\n",
    "    if 2020 in preds.forecast_time.dt.year:\n",
    "        obs_p = xr.open_dataset(f'{cache_path}/forecast-like-observations_2020_biweekly_terciled.nc').sel(forecast_time=preds.forecast_time)\n",
    "    else:\n",
    "        obs_p = xr.open_dataset(f'{cache_path}/hindcast-like-observations_2000-2019_biweekly_terciled.zarr', engine='zarr').sel(forecast_time=preds.forecast_time)\n",
    "    \n",
    "    # ML probabilities\n",
    "    fct_p = preds\n",
    "\n",
    "    \n",
    "    # climatology\n",
    "    clim_p = xr.DataArray([1/3, 1/3, 1/3], dims='category', coords={'category':['below normal', 'near normal', 'above normal']}).to_dataset(name='tp')\n",
    "    clim_p['t2m'] = clim_p['tp']\n",
    "    \n",
    "    if adapt:\n",
    "        # select only obs_p where fct_p forecasts provided\n",
    "        for c in ['longitude', 'latitude', 'forecast_time', 'lead_time']:\n",
    "            obs_p = obs_p.sel({c:fct_p[c]})\n",
    "        obs_p = obs_p[list(fct_p.data_vars)]\n",
    "        clim_p = clim_p[list(fct_p.data_vars)]\n",
    "    \n",
    "    else:\n",
    "        # check inputs\n",
    "        assert_predictions_2020(obs_p)\n",
    "        assert_predictions_2020(fct_p)\n",
    "    \n",
    "    ## RPSS\n",
    "    # rps_ML\n",
    "    rps_ML = xs.rps(obs_p, fct_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "    # rps_clim\n",
    "    rps_clim = xs.rps(obs_p, clim_p, category_edges=None, dim=[], input_distributions='p').compute()\n",
    "    \n",
    "    # rpss\n",
    "    rpss = 1 - (rps_ML / rps_clim)\n",
    "    \n",
    "    # https://renkulab.io/gitlab/aaron.spring/s2s-ai-challenge-template/-/issues/7\n",
    "\n",
    "    # penalize\n",
    "    penalize = obs_p.where(fct_p!=1, other=-10).mean('category')\n",
    "    rpss = rpss.where(penalize!=0, other=-10)\n",
    "\n",
    "    # clip\n",
    "    rpss = rpss.clip(-10, 1)\n",
    "\n",
    "    # average over all forecasts\n",
    "    rpss = rpss.groupby('forecast_time.year').mean()\n",
    "    \n",
    "    # weighted area mean\n",
    "    weights = np.cos(np.deg2rad(np.abs(rpss.latitude)))\n",
    "    # spatially weighted score averaged over lead_times and variables to one single value\n",
    "    scores = rpss.sel(latitude=slice(None, -60)).weighted(weights).mean('latitude').mean('longitude')\n",
    "    scores = scores.to_array()#.mean(['lead_time', 'variable'])\n",
    "    return scores.to_dataframe('RPSS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94636f3c-bb38-4439-89b6-01a9f880fbd3",
   "metadata": {},
   "source": [
    "### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c5c5c-3c98-4d79-a71d-c9f50e27e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read predictions on test year\n",
    "def load_pred(pred_folder, years):#, v, lead_output):\n",
    "    \n",
    "    das = []\n",
    "    for v in ['t2m', 'tp']:\n",
    "        if years == '2020':\n",
    "            das_lead0 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead0_{years}_smooth.nc')[v]#, chunks = {'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1})[v]#.chunk({'forecast_time':'auto','longitude': 'auto','latitude': 'auto'})\n",
    "            das_lead1 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead1_{years}_smooth.nc')[v]#, chunks = {'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1})[v]#.chunk({'forecast_time':'auto','longitude': 'auto','latitude': 'auto'})\n",
    "        else:\n",
    "            das_lead0 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead0_smooth_{years}.nc')[v]#.chunk({'forecast_time':'auto','longitude': 'auto','latitude': 'auto'})\n",
    "            das_lead1 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead1_smooth_{years}.nc')[v]#.chunk({'forecast_time':'auto','longitude': 'auto','latitude': 'auto'})\n",
    "        das.append(xr.concat([das_lead0, das_lead1], dim = 'lead_time'))#print(das)\n",
    "    return xr.merge(das)\n",
    "\n",
    "years = '2020'#'allyears'\n",
    "ds_24_10_2 = load_pred('24_10_2', years)#.chunk({'forecast_time':'auto','longitude': 'auto','latitude': 'auto'})\n",
    "ds_24_10_1 = load_pred('24_10_1', years)\n",
    "ds_25_10_1 = load_pred('25_10_1', years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f6392f-2813-48b4-9caf-d939f1e67404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skill for test year\n",
    "skill_24_10_2 = skill_by_year(ds_24_10_2, cache_path = '../../../../Data/s2s_ai/data')\n",
    "print(skill_24_10_2)\n",
    "\n",
    "skill_24_10_1 = skill_by_year(ds_24_10_1, cache_path = '../../../../Data/s2s_ai/data')\n",
    "print(skill_24_10_1)\n",
    "\n",
    "skill_25_10_1 = skill_by_year(ds_25_10_1, cache_path = '../../../../Data/s2s_ai/data')\n",
    "print(skill_25_10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c17a3a-9e95-4d4a-a7f8-8a8da3e762e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is too big if executed on training data on local computer\n",
    "average_pred_2020 = xr.concat([ds_24_10_1.expand_dims(dim={'pred': ['24_10_11']}).chunk({'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1}), \n",
    "                          ds_24_10_2.expand_dims(dim={'pred': ['24_10_2']}).chunk({'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1}), \n",
    "                          ds_25_10_1.expand_dims(dim={'pred': ['25_10_1']}).chunk({'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1})],'pred').mean('pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe13f2a-7a85-40f0-84f2-247215bddd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_average_2020 = skill_by_year(average_pred_2020, cache_path = '../../../../Data/s2s_ai/data')\n",
    "print(skill_average_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26791ca2-656b-4e36-8643-4c45bccc4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skill_by_year_old(average_pred_2020, cache_path = '../../../../Data/s2s_ai/data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d0d64-2872-41cf-810e-27582cbaeb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "v= 't2m'\n",
    "lead_output = 0\n",
    "\n",
    "fct_p = average_pred_2020.isel(lead_time = lead_output)\n",
    "if 2020 in fct_p.forecast_time.dt.year:\n",
    "    obs_p = load_data(data = 'obs_terciled_2020', aggregation = 'biweekly', path = path_data).isel(lead_time = lead_output)[v]\n",
    "else:\n",
    "    obs_p = load_data(data = 'obs_terciled_2000-2019', aggregation = 'biweekly', path = path_data).isel(lead_time = lead_output)[v]\n",
    "\n",
    "\n",
    "rpss = gridcellwise_rpss(fct_p[v], obs_p,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233656d3-d76b-4203-bda1-582edbdbd579",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rpss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72d0e0-1422-445a-ae52-70f97099143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "rpss.mean('forecast_time').plot()\n",
    "\n",
    "plt.figure()\n",
    "rpss.mean(('latitude','longitude')).plot()\n",
    "plt.hlines(y = 0, \n",
    "           xmin = rpss.isel(forecast_time = 0).forecast_time.values, \n",
    "           xmax = rpss.isel(forecast_time  = -1).forecast_time.values,\n",
    "           color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5dd1db-ab32-41f4-a52f-3e2738b4ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v= 't2m'\n",
    "lead_output = 1\n",
    "\n",
    "fct_p = average_pred_2020.isel(lead_time = lead_output)\n",
    "if 2020 in fct_p.forecast_time.dt.year:\n",
    "    obs_p = load_data(data = 'obs_terciled_2020', aggregation = 'biweekly', path = path_data).isel(lead_time = lead_output)[v]\n",
    "else:\n",
    "    obs_p = load_data(data = 'obs_terciled_2000-2019', aggregation = 'biweekly', path = path_data).isel(lead_time = lead_output)[v]\n",
    "\n",
    "\n",
    "rpss = gridcellwise_rpss(fct_p[v], obs_p,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cc0bd-fb03-42c6-ae3e-bb17eea155b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rpss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847161c-f777-4d99-b928-b5e978c12873",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "rpss.mean('forecast_time').plot()\n",
    "\n",
    "plt.figure()\n",
    "rpss.mean(('latitude','longitude')).plot()\n",
    "plt.hlines(y = 0, \n",
    "           xmin = rpss.isel(forecast_time = 0).forecast_time.values, \n",
    "           xmax = rpss.isel(forecast_time  = -1).forecast_time.values,\n",
    "           color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158560b-2548-4c09-bf59-e72c906fd5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bcef9-dd8e-4a0e-a70b-589110c28827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bd42f-713d-473b-842e-c86d1a78f210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29175441-78ed-426c-b04c-e303664985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpss_single = skill_by_year_byvar_andlead(average_pred_2020, adapt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679dd89-3e8e-4948-82dc-cf7b4ac69dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rpss_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631581fc-7a9c-45a9-8d09-10ef26617814",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpss_single.droplevel(1).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cd804-d9c1-428d-8389-92b50aa006f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpss_single_old = skill_by_year_old_single(average_pred_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354aa91c-410b-4c29-b19f-be2e5591db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpss_single_old.droplevel(1).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996dbf5-c36b-49ec-aad3-8b2c356735d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpss_single_old.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8052e-5a8b-4939-8ccf-1d79f58639cc",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c93f4e-12aa-4075-93aa-761c6306ccc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc43fd-2631-4893-95ec-ea21fd89d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 'allyears'\n",
    "ds_24_10_2 = load_pred('24_10_2', years)#.chunk({'forecast_time':'auto','longitude': 'auto','latitude': 'auto'})\n",
    "ds_24_10_1 = load_pred('24_10_1', years)\n",
    "ds_25_10_1 = load_pred('25_10_1', years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a3a7a-1219-4e41-8693-89fece44182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is too big if executed on training data on local computer\n",
    "average_pred = xr.concat([ds_24_10_1.expand_dims(dim={'pred': ['24_10_11']}).chunk({'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1}), \n",
    "                          ds_24_10_2.expand_dims(dim={'pred': ['24_10_2']}).chunk({'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1}), \n",
    "                          ds_25_10_1.expand_dims(dim={'pred': ['25_10_1']}).chunk({'forecast_time':'auto','longitude': 24,'latitude': 'auto', 'category': 1})],'pred').mean('pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5275f0-8e3e-4768-8787-b346fe699e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skill for train years\n",
    "skill_24_10_2 = skill_by_year(ds_24_10_2, cache_path = '../../../../Data/s2s_ai/data')\n",
    "print(skill_24_10_2)\n",
    "\n",
    "skill_24_10_1 = skill_by_year(ds_24_10_1, cache_path = '../../../../Data/s2s_ai/data')\n",
    "print(skill_24_10_1)\n",
    "\n",
    "skill_25_10_1 = skill_by_year(ds_25_10_1, cache_path = '../../../../Data/s2s_ai/data')\n",
    "print(skill_25_10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfec09a-159a-42a1-b77f-8d554360290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_average = skill_by_year(average_pred, cache_path = '../../../../Data/s2s_ai/data', adapt=True)\n",
    "print(skill_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a4f08-fcea-47d3-8605-60f5c273ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fct_p = average_pred.isel(lead_time = 0)\n",
    "if 2020 in fct_p.forecast_time.dt.year:\n",
    "    obs_p = load_data(data = 'obs_terciled_2020', aggregation = 'biweekly', path = path_data).isel(lead_time = lead_output)[v]\n",
    "else:\n",
    "    obs_p = load_data(data = 'obs_terciled_2000-2019', aggregation = 'biweekly', path = path_data).isel(lead_time = lead_output)[v]\n",
    "\n",
    "\n",
    "\n",
    "rpss = gridcellwise_rpss(fct_p[v], obs_p,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2317e-7f1e-4871-a6c1-08af4b823db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "rpss.mean('forecast_time').plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffefe45-5eed-4d0d-ab70-534bff8eb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "rpss.mean(('latitude','longitude')).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b7ec3-384f-4d42-885d-397ba431989c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabe615-2592-4a1a-8cf1-506c90676df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27383442-42b9-43c1-a03c-fb57360ffd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
