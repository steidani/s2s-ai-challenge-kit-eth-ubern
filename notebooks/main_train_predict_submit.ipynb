{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML model for predictions of week 3-4 & 5-6\n",
    "\n",
    "This notebook create a Machine Learning `ML_model` to predict weeks 3-4 & 5-6 based on `S2S` weeks 3-4 & 5-6 forecasts and is compared to `CPC` observations for the [`s2s-ai-challenge`](https://s2s-ai-challenge.github.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: `local convolutional neural network`\n",
    "We developed a `local convolutional neural network` to tackle this challenge task. Our approach is based on a simplified version of a convolutional neural network architecture that was proposed in Scheuerer et al. 2020. We trained one model for each variable and lead time, i.e., 4 models in total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used\n",
    "\n",
    "Training-input for Machine Learning model:\n",
    "- renku datasets: all hindcasts of the target variables and the tercile edges for the features and all terciled hindcast-like-observations as labels\n",
    "\n",
    "Forecast-input for Machine Learning model:\n",
    "- renku datasets: all forecasts of the target variables and the tercile edges\n",
    "\n",
    "Compare Machine Learning model forecast against ground truth:\n",
    "- renku datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources used\n",
    "see reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safeguards\n",
    "\n",
    "All points have to be [x] checked. If not, your submission is invalid.\n",
    "\n",
    "Changes to the code after submissions are not possible, as the `commit` before the `tag` will be reviewed.\n",
    "(Only in exceptions and if previous effort in reproducibility can be found, it may be allowed to improve readability and reproducibility after November 1st 2021.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safeguards to prevent [overfitting](https://en.wikipedia.org/wiki/Overfitting?wprov=sfti1) \n",
    "\n",
    "If the organizers suspect overfitting, your contribution can be disqualified.\n",
    "\n",
    "  - [X] We did not use 2020 observations in training (explicit overfitting and cheating)\n",
    "  - [X] We did not repeatedly verify my model on 2020 observations and incrementally improved my RPSS (implicit overfitting)\n",
    "  - [X] We provide RPSS scores for the training period with script `skill_by_year`, see section 5.1\n",
    "  - [X] We tried our best to prevent [data leakage](https://en.wikipedia.org/wiki/Leakage_(machine_learning)?wprov=sfti1).\n",
    "  - [X] We honor the `train-validate-test` [split principle](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets). This means that the hindcast data is split into `train` and `validate`, whereas `test` is withheld.\n",
    "  - [X] We did not use `test` explicitly in training or implicitly in incrementally adjusting parameters.\n",
    "  - [X] We considered [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safeguards for Reproducibility\n",
    "Notebook/code must be independently reproducible from scratch by the organizers (after the competition), if not possible: no prize\n",
    "  - [X] All training data is publicly available (no pre-trained private neural networks, as they are not reproducible for us)\n",
    "  - [X] Code is well documented, readable and reproducible.\n",
    "  - [X] Code to reproduce training and predictions is preferred to run within a day on the described architecture. If the training takes longer than a day, please justify why this is needed. Please do not submit training piplelines, which take weeks to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda activate s2s-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to run CNN_train_predict.py using the data in the repo, set data_path to horat_n. The line below is used to run the script on the server, where the data was stored in a different folder which is not backed up.\n",
    "# takes about 12 h using 25 cores on the specified architecture\n",
    "# run file CNN_train_predict.py to create an ensemble of 5 predictions\n",
    "# ! taskset --cpu-list 21-45 python CNN_train_predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "xr.set_options(display_style='text')\n",
    "\n",
    "from scripts import skill_by_year, assert_predictions_2020\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") \n",
    "\n",
    "path_data = 'server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred(pred_folder, years):\n",
    "    \n",
    "    das = []\n",
    "    for v in ['t2m', 'tp']:\n",
    "        if years == '2020':\n",
    "            das_lead0 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead0_{years}_smooth.nc')[v]\n",
    "            das_lead1 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead1_{years}_smooth.nc')[v]\n",
    "        else:\n",
    "            das_lead0 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead0_smooth_{years}.nc')[v]\n",
    "            das_lead1 = xr.open_dataset(f'../submissions/{pred_folder}/global_prediction_{v}_lead1_smooth_{years}.nc')[v]\n",
    "        das.append(xr.concat([das_lead0, das_lead1], dim = 'lead_time'))\n",
    "    return xr.merge(das).expand_dims(dim={'pred': [pred_folder]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read predictions for test year\n",
    "years = '2020'\n",
    "ds_10 = load_pred('10', years)\n",
    "ds_20 = load_pred('20', years)\n",
    "ds_30 = load_pred('30', years)\n",
    "ds_40 = load_pred('40', years)\n",
    "ds_50 = load_pred('50', years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average over different predictions (obtained using different seeds)\n",
    "average_pred_2020 = xr.concat([ds_10, ds_20, ds_30, ds_40, ds_50], 'pred').mean('pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:        (forecast_time: 53, category: 3, latitude: 121, longitude: 240, lead_time: 2)\n",
       "Coordinates:\n",
       "  * forecast_time  (forecast_time) datetime64[ns] 2020-01-02 ... 2020-12-31\n",
       "  * category       (category) object &#x27;below normal&#x27; &#x27;near normal&#x27; &#x27;above normal&#x27;\n",
       "  * latitude       (latitude) float64 90.0 88.5 87.0 85.5 ... -87.0 -88.5 -90.0\n",
       "  * longitude      (longitude) float64 0.0 1.5 3.0 4.5 ... 355.5 357.0 358.5\n",
       "  * lead_time      (lead_time) timedelta64[ns] 14 days 28 days\n",
       "Data variables:\n",
       "    t2m            (lead_time, category, forecast_time, latitude, longitude) float64 ...\n",
       "    tp             (lead_time, category, forecast_time, latitude, longitude) float64 ...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (forecast_time: 53, category: 3, latitude: 121, longitude: 240, lead_time: 2)\n",
       "Coordinates:\n",
       "  * forecast_time  (forecast_time) datetime64[ns] 2020-01-02 ... 2020-12-31\n",
       "  * category       (category) object 'below normal' 'near normal' 'above normal'\n",
       "  * latitude       (latitude) float64 90.0 88.5 87.0 85.5 ... -87.0 -88.5 -90.0\n",
       "  * longitude      (longitude) float64 0.0 1.5 3.0 4.5 ... 355.5 357.0 358.5\n",
       "  * lead_time      (lead_time) timedelta64[ns] 14 days 28 days\n",
       "Data variables:\n",
       "    t2m            (lead_time, category, forecast_time, latitude, longitude) float64 ...\n",
       "    tp             (lead_time, category, forecast_time, latitude, longitude) float64 ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_pred_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save average prediction as final prediction\n",
    "average_pred_2020.to_netcdf(f'../submissions/ML_prediction_2020.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git add ../submissions/ML_prediction_2020.nc\n",
    "#!git add ML_forecast_template.ipynb\n",
    "\n",
    "#!git commit -m \"commit submission for my_method_name\" # whatever message you want\n",
    "#!git tag \"submission-my_method_name-0.0.1\" # if this is to be checked by scorer, only the last submitted==tagged version will be considered\n",
    "\n",
    "#!git push --tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RPSS\n",
      "year          \n",
      "2020  0.002364\n"
     ]
    }
   ],
   "source": [
    "skill_average_2020 = skill_by_year(average_pred_2020, cache_path = '../../../../Data/s2s_ai/data')#the data was stored in a different folder which is not backed up\n",
    "print(skill_average_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPSS for training period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read predictions for train years\n",
    "years = 'allyears'\n",
    "ds_train_10 = load_pred('10', years)\n",
    "ds_train_20 = load_pred('20', years)\n",
    "ds_train_30 = load_pred('30', years)\n",
    "ds_train_40 = load_pred('40', years)\n",
    "ds_train_50 = load_pred('50', years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average over different predictions (obtained using different seeds)\n",
    "average_pred_train = xr.concat([ds_train_10, ds_train_20, ds_train_30, ds_train_40, ds_train_50], 'pred').mean('pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RPSS\n",
      "year          \n",
      "2000  0.008699\n",
      "2001  0.004106\n",
      "2002  0.003021\n",
      "2003  0.003090\n",
      "2004  0.003638\n",
      "2005  0.001265\n",
      "2006  0.002902\n",
      "2007  0.002793\n",
      "2008  0.004395\n",
      "2009  0.000433\n",
      "2010  0.000719\n",
      "2011  0.003563\n",
      "2012  0.002182\n",
      "2013  0.001284\n",
      "2014  0.001288\n",
      "2015 -0.000021\n",
      "2016 -0.000114\n",
      "2017 -0.000091\n",
      "2018  0.001625\n",
      "2019  0.000519\n"
     ]
    }
   ],
   "source": [
    "skill_average_train = skill_by_year(average_pred_train, cache_path = '../../../../Data/s2s_ai/data')#the data was stored in a different folder which is not backed up\n",
    "print(skill_average_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPSS    0.002265\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(skill_average_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            236          72          35           1         127         160\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "# https://phoenixnap.com/kb/linux-commands-check-memory-usage\n",
    "!free -g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\n",
      "CPU op-mode(s):      32-bit, 64-bit\n",
      "Byte Order:          Little Endian\n",
      "Address sizes:       46 bits physical, 48 bits virtual\n",
      "CPU(s):              48\n",
      "On-line CPU(s) list: 0-47\n",
      "Thread(s) per core:  2\n",
      "Core(s) per socket:  12\n",
      "Socket(s):           2\n",
      "NUMA node(s):        2\n",
      "Vendor ID:           GenuineIntel\n",
      "CPU family:          6\n",
      "Model:               63\n",
      "Model name:          Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz\n",
      "Stepping:            2\n",
      "CPU MHz:             2500.704\n",
      "CPU max MHz:         3300,0000\n",
      "CPU min MHz:         1200,0000\n",
      "BogoMIPS:            5000.30\n",
      "Virtualization:      VT-x\n",
      "L1d cache:           32K\n",
      "L1i cache:           32K\n",
      "L2 cache:            256K\n",
      "L3 cache:            30720K\n",
      "NUMA node0 CPU(s):   0-11,24-35\n",
      "NUMA node1 CPU(s):   12-23,36-47\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm abm cpuid_fault epb invpcid_single pti intel_ppin tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: conda: not found\n"
     ]
    }
   ],
   "source": [
    "!conda list\n",
    "#this seems not to work, so see the copied output below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name                    Version                   Build  Channel\n",
    "_libgcc_mutex             0.1                        main  \n",
    "_openmp_mutex             4.5                       1_gnu  \n",
    "_pytorch_select           0.1                       cpu_0  \n",
    "_tflow_select             2.3.0                       mkl  \n",
    "abseil-cpp                20200923.3           h2531618_0  \n",
    "absl-py                   0.13.0           py39h06a4308_0  \n",
    "aiobotocore               1.3.3              pyhd3eb1b0_0  \n",
    "aiohttp                   3.7.4            py39h27cfd23_1  \n",
    "aioitertools              0.7.1              pyhd3eb1b0_0  \n",
    "appdirs                   1.4.4              pyhd3eb1b0_0  \n",
    "asciitree                 0.3.3                      py_2  \n",
    "astor                     0.8.1            py39h06a4308_0  \n",
    "astunparse                1.6.3                      py_0  \n",
    "async-timeout             3.0.1            py39h06a4308_0  \n",
    "attrs                     21.2.0             pyhd3eb1b0_0  \n",
    "backcall                  0.2.0              pyhd3eb1b0_0  \n",
    "beautifulsoup4            4.10.0             pyha770c72_0    conda-forge\n",
    "blas                      1.0                         mkl  \n",
    "blinker                   1.4              py39h06a4308_0  \n",
    "bokeh                     2.3.3            py39h06a4308_0  \n",
    "botocore                  1.20.106           pyhd3eb1b0_0  \n",
    "bottleneck                1.3.2            py39hdd57654_1  \n",
    "branca                    0.3.1                    pypi_0    pypi\n",
    "brotli                    1.0.9                he6710b0_2  \n",
    "brotlipy                  0.7.0           py39h27cfd23_1003  \n",
    "bzip2                     1.0.8                h7f98852_4    conda-forge\n",
    "c-ares                    1.17.1               h27cfd23_0  \n",
    "ca-certificates           2021.5.30            ha878542_0    conda-forge\n",
    "cached-property           1.5.2                      py_0  \n",
    "cachetools                4.2.2              pyhd3eb1b0_0  \n",
    "cdsapi                    0.5.1                    pypi_0    pypi\n",
    "certifi                   2021.5.30        py39hf3d152e_0    conda-forge\n",
    "cffi                      1.14.6           py39h400218f_0  \n",
    "cfgrib                    0.9.9.0            pyhd8ed1ab_1    conda-forge\n",
    "cftime                    1.5.0            py39h6323ea4_0  \n",
    "chardet                   3.0.4           py39h06a4308_1003  \n",
    "charset-normalizer        2.0.4              pyhd3eb1b0_0  \n",
    "click                     8.0.1              pyhd3eb1b0_0  \n",
    "climetlab                 0.8.18                   pypi_0    pypi\n",
    "climetlab-s2s-ai-challenge 0.8.0                    pypi_0    pypi\n",
    "cloudpickle               1.6.0              pyhd3eb1b0_0  \n",
    "configargparse            1.5.2                    pypi_0    pypi\n",
    "coverage                  5.5              py39h27cfd23_2  \n",
    "cryptography              3.4.7            py39hd23ed53_0  \n",
    "curl                      7.78.0               h1ccaba5_0  \n",
    "cycler                    0.10.0           py39h06a4308_0  \n",
    "cython                    0.29.24          py39h295c915_0  \n",
    "cytoolz                   0.11.0           py39h27cfd23_0  \n",
    "dask                      2021.8.1           pyhd3eb1b0_0  \n",
    "dask-core                 2021.8.1           pyhd3eb1b0_0  \n",
    "debugpy                   1.4.1            py39h295c915_0  \n",
    "decorator                 5.0.9              pyhd3eb1b0_0  \n",
    "distributed               2021.8.1         py39h06a4308_0  \n",
    "docopt                    0.6.2                      py_1    conda-forge\n",
    "eccodes                   2.19.1               hea64003_0    conda-forge\n",
    "ecmwf-api-client          1.6.1                    pypi_0    pypi\n",
    "ecmwflibs                 0.3.14                   pypi_0    pypi\n",
    "entrypoints               0.3              py39h06a4308_0  \n",
    "fasteners                 0.16.3             pyhd3eb1b0_0  \n",
    "findlibs                  0.0.2                    pypi_0    pypi\n",
    "flatbuffers               2.0.0                h2531618_0  \n",
    "folium                    0.12.1                   pypi_0    pypi\n",
    "fonttools                 4.25.0             pyhd3eb1b0_0  \n",
    "freetype                  2.10.4               h5ab3b9f_0  \n",
    "fsspec                    2021.7.0           pyhd3eb1b0_0  \n",
    "gast                      0.4.0              pyhd3eb1b0_0  \n",
    "giflib                    5.2.1                h7b6447c_0  \n",
    "google-auth               1.33.0             pyhd3eb1b0_0  \n",
    "google-auth-oauthlib      0.4.1                      py_2  \n",
    "google-pasta              0.2.0              pyhd3eb1b0_0  \n",
    "grpcio                    1.36.1           py39h2157cd5_1  \n",
    "h5netcdf                  0.11.0             pyhd8ed1ab_0    conda-forge\n",
    "h5py                      2.10.0           py39hec9cf62_0  \n",
    "hdf4                      4.2.13               h3ca952b_2  \n",
    "hdf5                      1.10.6          nompi_h7c3c948_1111    conda-forge\n",
    "heapdict                  1.0.1              pyhd3eb1b0_0  \n",
    "icu                       68.1                 h2531618_0  \n",
    "idna                      3.2                pyhd3eb1b0_0  \n",
    "importlib-metadata        3.10.0           py39h06a4308_0  \n",
    "intake                    0.6.3              pyhd3eb1b0_0  \n",
    "intake-xarray             0.5.0              pyhd3eb1b0_0  \n",
    "intel-openmp              2019.4                      243  \n",
    "ipykernel                 6.2.0            py39h06a4308_1  \n",
    "ipython                   7.26.0           py39hb070fc8_0  \n",
    "ipython_genutils          0.2.0              pyhd3eb1b0_1  \n",
    "jasper                    1.900.1           h07fcdf6_1006    conda-forge\n",
    "jedi                      0.18.0           py39h06a4308_1  \n",
    "jellyfish                 0.8.8                    pypi_0    pypi\n",
    "jinja2                    3.0.1              pyhd3eb1b0_0  \n",
    "jmespath                  0.10.0             pyhd3eb1b0_0  \n",
    "joblib                    1.0.1              pyhd8ed1ab_0    conda-forge\n",
    "jpeg                      9d                   h36c2ea0_0    conda-forge\n",
    "jupyter_client            7.0.1              pyhd3eb1b0_0  \n",
    "jupyter_core              4.7.1            py39h06a4308_0  \n",
    "keras-preprocessing       1.1.2              pyhd3eb1b0_0  \n",
    "kiwisolver                1.3.1            py39h2531618_0  \n",
    "krb5                      1.19.2               hac12032_0  \n",
    "lcms2                     2.12                 h3be6417_0  \n",
    "ld_impl_linux-64          2.35.1               h7274673_9  \n",
    "libaec                    1.0.5                h9c3ff4c_0    conda-forge\n",
    "libcurl                   7.78.0               h0b77cf5_0  \n",
    "libedit                   3.1.20210714         h7f8727e_0  \n",
    "libev                     4.33                 h7b6447c_0  \n",
    "libffi                    3.3                  he6710b0_2  \n",
    "libgcc-ng                 9.3.0               h5101ec6_17  \n",
    "libgfortran-ng            7.5.0               ha8ba4b0_17  \n",
    "libgfortran4              7.5.0               ha8ba4b0_17  \n",
    "libgomp                   9.3.0               h5101ec6_17  \n",
    "libllvm10                 10.0.1               he513fc3_3    conda-forge\n",
    "libmklml                  2019.0.5                      0  \n",
    "libnetcdf                 4.7.4           nompi_h56d31a8_107    conda-forge\n",
    "libnghttp2                1.41.0               hf8bcb03_2  \n",
    "libpng                    1.6.37               hbc83047_0  \n",
    "libprotobuf               3.14.0               h8c45485_0  \n",
    "libsodium                 1.0.18               h7b6447c_0  \n",
    "libssh2                   1.9.0                h1ba5d50_1  \n",
    "libstdcxx-ng              9.3.0               hd4cf53a_17  \n",
    "libtiff                   4.2.0                h85742a9_0  \n",
    "libwebp                   1.2.0                h89dd481_0  \n",
    "libwebp-base              1.2.0                h27cfd23_0  \n",
    "llvmlite                  0.36.0           py39h612dafd_4  \n",
    "locket                    0.2.1            py39h06a4308_1  \n",
    "lz4-c                     1.9.3                h295c915_1  \n",
    "magics                    1.5.6                    pypi_0    pypi\n",
    "markdown                  3.3.4            py39h06a4308_0  \n",
    "markupsafe                2.0.1            py39h27cfd23_0  \n",
    "matplotlib-base           3.4.2            py39hab158f2_0  \n",
    "matplotlib-inline         0.1.2              pyhd3eb1b0_2  \n",
    "mkl                       2020.2                      256  \n",
    "mkl-service               2.3.0            py39he8ac12f_0  \n",
    "mkl_fft                   1.3.0            py39h54f3939_0  \n",
    "mkl_random                1.0.2            py39h63df603_0  \n",
    "msgpack-python            1.0.2            py39hff7bd54_1  \n",
    "multidict                 5.1.0            py39h27cfd23_2  \n",
    "munkres                   1.1.4                      py_0  \n",
    "nc-time-axis              1.3.1              pyhd8ed1ab_2    conda-forge\n",
    "ncurses                   6.2                  he6710b0_1  \n",
    "nest-asyncio              1.5.1              pyhd3eb1b0_0  \n",
    "netcdf4                   1.5.4           nompi_py39hb3be4b9_103    conda-forge\n",
    "ninja                     1.10.2               hff7bd54_1  \n",
    "numba                     0.53.1           py39ha9443f7_0  \n",
    "numcodecs                 0.8.0            py39h2531618_0  \n",
    "numexpr                   2.7.3            py39hb2eb853_0  \n",
    "numpy                     1.19.2           py39h89c1606_0  \n",
    "numpy-base                1.19.2           py39h2ae0177_0  \n",
    "oauthlib                  3.1.1              pyhd3eb1b0_0  \n",
    "olefile                   0.46               pyhd3eb1b0_0  \n",
    "openssl                   1.1.1k               h7f98852_0    conda-forge\n",
    "opt_einsum                3.3.0              pyhd3eb1b0_1  \n",
    "packaging                 21.0               pyhd3eb1b0_0  \n",
    "pandas                    1.3.2            py39h8c16a72_0  \n",
    "parso                     0.8.2              pyhd3eb1b0_0  \n",
    "partd                     1.2.0              pyhd3eb1b0_0  \n",
    "pdbufr                    0.9.0                    pypi_0    pypi\n",
    "pexpect                   4.8.0              pyhd3eb1b0_3  \n",
    "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
    "pillow                    8.3.1            py39h5aabda8_0  \n",
    "pip                       21.2.4           py37h06a4308_0  \n",
    "prompt-toolkit            3.0.17             pyhca03da5_0  \n",
    "properscoring             0.1                        py_0    conda-forge\n",
    "protobuf                  3.14.0           py39h2531618_1  \n",
    "psutil                    5.8.0            py39h27cfd23_1  \n",
    "ptyprocess                0.7.0              pyhd3eb1b0_2  \n",
    "pyasn1                    0.4.8              pyhd3eb1b0_0  \n",
    "pyasn1-modules            0.2.8                      py_0  \n",
    "pycparser                 2.20                       py_2  \n",
    "pydap                     3.2.2           pyh9f0ad1d_1001    conda-forge\n",
    "pygments                  2.10.0             pyhd3eb1b0_0  \n",
    "pyjwt                     2.1.0            py39h06a4308_0  \n",
    "pyodc                     1.0.3                    pypi_0    pypi\n",
    "pyopenssl                 20.0.1             pyhd3eb1b0_1  \n",
    "pyparsing                 2.4.7              pyhd3eb1b0_0  \n",
    "pysocks                   1.7.1            py39h06a4308_0  \n",
    "python                    3.9.6                h12debd9_1  \n",
    "python-dateutil           2.8.2              pyhd3eb1b0_0  \n",
    "python-eccodes            2020.10.0        py39h1dff97c_0    conda-forge\n",
    "python-flatbuffers        1.12               pyhd3eb1b0_0  \n",
    "python-snappy             0.6.0            py39h2531618_3  \n",
    "python_abi                3.9                      2_cp39    conda-forge\n",
    "pytorch                   1.8.1           cpu_py39h60491be_0  \n",
    "pytz                      2021.1             pyhd3eb1b0_0  \n",
    "pyyaml                    5.4.1            py39h27cfd23_1  \n",
    "pyzmq                     22.2.1           py39h295c915_1  \n",
    "readline                  8.1                  h27cfd23_0  \n",
    "requests                  2.26.0             pyhd3eb1b0_0  \n",
    "requests-oauthlib         1.3.0                      py_0  \n",
    "rsa                       4.7.2              pyhd3eb1b0_1  \n",
    "s3fs                      2021.7.0           pyhd3eb1b0_0  \n",
    "scikit-learn              0.24.2           py39ha9443f7_0  \n",
    "scipy                     1.6.2            py39h91f5cce_0  \n",
    "setuptools                52.0.0           py39h06a4308_0  \n",
    "six                       1.16.0             pyhd3eb1b0_0  \n",
    "snappy                    1.1.8                he6710b0_0  \n",
    "sortedcontainers          2.4.0              pyhd3eb1b0_0  \n",
    "soupsieve                 2.0.1                      py_1    conda-forge\n",
    "sqlite                    3.36.0               hc218d9a_0  \n",
    "tbb                       2020.2               h4bd325d_4    conda-forge\n",
    "tblib                     1.7.0              pyhd3eb1b0_0  \n",
    "tensorboard               2.5.0                      py_0  \n",
    "tensorboard-plugin-wit    1.6.0                      py_0  \n",
    "tensorflow                2.4.1           mkl_py39h4683426_0  \n",
    "tensorflow-base           2.4.1           mkl_py39h43e0292_0  \n",
    "tensorflow-estimator      2.5.0              pyh7b7c402_0  \n",
    "termcolor                 1.1.0            py39h06a4308_1  \n",
    "threadpoolctl             2.2.0              pyh8a188c0_0    conda-forge\n",
    "tk                        8.6.10               hbc83047_0  \n",
    "toolz                     0.11.1             pyhd3eb1b0_0  \n",
    "tornado                   6.1              py39h27cfd23_0  \n",
    "tqdm                      4.62.2                   pypi_0    pypi\n",
    "traitlets                 5.0.5              pyhd3eb1b0_0  \n",
    "typing-extensions         3.10.0.0             hd3eb1b0_0  \n",
    "typing_extensions         3.10.0.0           pyh06a4308_0  \n",
    "tzdata                    2021a                h5d7bf9c_0  \n",
    "urllib3                   1.26.6             pyhd3eb1b0_1  \n",
    "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
    "webob                     1.8.7              pyhd8ed1ab_0    conda-forge\n",
    "werkzeug                  1.0.1              pyhd3eb1b0_0  \n",
    "wheel                     0.35.1             pyhd3eb1b0_0  \n",
    "wrapt                     1.12.1           py39he8ac12f_1  \n",
    "xarray                    0.19.0             pyhd3eb1b0_1  \n",
    "xhistogram                0.3.0              pyhd8ed1ab_0    conda-forge\n",
    "xskillscore               0.0.23             pyhd8ed1ab_0    conda-forge\n",
    "xz                        5.2.5                h7b6447c_0  \n",
    "yaml                      0.2.5                h7b6447c_0  \n",
    "yarl                      1.6.3            py39h27cfd23_0  \n",
    "zarr                      2.8.1              pyhd3eb1b0_0  \n",
    "zeromq                    4.3.4                h2531618_0  \n",
    "zict                      2.0.0              pyhd3eb1b0_0  \n",
    "zipp                      3.5.0              pyhd3eb1b0_0  \n",
    "zlib                      1.2.11               h7b6447c_3  \n",
    "zstd                      1.4.9                haebb681_0  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2s-ai-python-kernel",
   "language": "python",
   "name": "s2s-ai-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
